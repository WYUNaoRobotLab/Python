{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\studyINF\\data\\new\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"error\")\n",
    "import h5py\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dict_class(path):\n",
    "    dict_classes = dict()\n",
    "    pattern = \"(.+):(\\\\d+)\"\n",
    "    with open(path,\"r\") as f:\n",
    "        while True:\n",
    "            line_str =f.readline()\n",
    "            if line_str == \"\":\n",
    "                break\n",
    "            else:\n",
    "                 key,value = re.findall(pattern,line_str)[0]\n",
    "                 dict_classes[key] = int(value)\n",
    "    return dict_classes\n",
    "\n",
    "\n",
    "def get_coordinates(original_string):\n",
    "    xmin = re.findall('<xmin>(\\\\d+)</xmin>', original_string)\n",
    "    ymin = re.findall('<ymin>(\\\\d+)</ymin>', original_string)\n",
    "    xmax = re.findall('<xmax>(\\\\d+)</xmax>', original_string)\n",
    "    ymax = re.findall('<ymax>(\\\\d+)</ymax>', original_string)\n",
    "    try:\n",
    "        assert(len(xmin) == len(ymin) and len(ymin) == len(xmax) and len(xmax) == len(ymax))\n",
    "    except:\n",
    "        print(original_string)\n",
    "        return 0\n",
    "    for i in range(len(xmin)):\n",
    "        xmin[i] = int(xmin[i])\n",
    "        ymin[i] = int(ymin[i])\n",
    "        xmax[i] = int(xmax[i])\n",
    "        ymax[i] = int(ymax[i])\n",
    "    xmin = np.array(xmin,dtype=np.int32)\n",
    "    ymin = np.array(ymin,dtype=np.int32)\n",
    "    xmax = np.array(xmax,dtype=np.int32)\n",
    "    ymax = np.array(ymax,dtype=np.int32)\n",
    "\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "def read_content(xmlfile):\n",
    "    with open(xmlfile,\"r\",encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "def start(xmllist):\n",
    "    counter = 0\n",
    "    for xmlfile in xmllist:\n",
    "        counter+=1\n",
    "        content = read_content(xmlfile)\n",
    "        xmin, ymin, xmax, ymax = get_coordinates(content)\n",
    "        if counter != 1:\n",
    "            np_xmin = np.concatenate((np_xmin,xmin))\n",
    "            np_xmax = np.concatenate((np_xmax,xmax))\n",
    "            np_ymin = np.concatenate((np_ymin,ymin))\n",
    "            np_ymax = np.concatenate((np_ymax,ymax))\n",
    "        else:\n",
    "            np_xmin = xmin\n",
    "            np_xmax = xmax\n",
    "            np_ymin = ymin\n",
    "            np_ymax = ymax\n",
    "    return  np_xmin, np_xmax, np_ymin, np_ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class cluster_anchor():\n",
    "    def __init__(self, complete_size, k):\n",
    "        \"\"\"\n",
    "        k is amount of cluster\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.sample_location = [None for i in range(complete_size.shape[0])]  # 用以记录每个样本在哪个类\n",
    "        self.complete_size = complete_size\n",
    "\n",
    "        self.list_cluster = [None for i in range(k)]  # 用以记录每个类的样本的序号\n",
    "        self.clustering()\n",
    "        self.calculate_all_center()\n",
    "\n",
    "\n",
    "    def clustering(self):\n",
    "        amount_sample = self.complete_size.shape[0]\n",
    "        for i in range(self.k):\n",
    "            self.list_cluster[i] = np.array([i])\n",
    "            self.sample_location[i] = i\n",
    "        self.counter = amount_sample  # counter 是每次迭代中，移动的样本的个数，若其小与样本总数的5%，则可结束循环\n",
    "        while self.counter > 0 * amount_sample:\n",
    "            self.counter = 0\n",
    "            for i in range(amount_sample):\n",
    "                self.partition(i)  # 将该样本划分到某一个类里\n",
    "        #print(self.list_cluster)\n",
    "\n",
    "    def calculate_all_center(self):\n",
    "        self.center_list = [0 for i in range(self.k)]\n",
    "        for i in range(self.k):\n",
    "            self.center_list[i] = self.cal_mean(self.list_cluster[i]) # 计算每个类的中心，即平均的(width,height)\n",
    "\n",
    "    def partition(self, i):\n",
    "\n",
    "        iou = [None for z in range(self.k)]\n",
    "        for j in range(self.k):\n",
    "            mean_ = self.cal_mean(self.list_cluster[j])  # 得到每个类的中心\n",
    "            iou[j] = self.calculate_iou(self.complete_size[i], mean_)\n",
    "        index = np.argmax(np.array(iou))  # iou 最大值的位置,即对应最大的类\n",
    "        if index != self.sample_location[i] :  # 如果不在原本的类中\n",
    "            if self.sample_location[i] is not None:\n",
    "                if  iou[self.sample_location[i]] != iou[index]:  # 防止进行不必要的转移，因为index指向的类的中心与样本的距离，与原本类中心的距离相同\n",
    "                    self.list_cluster[self.sample_location[i]] = np.delete(self.list_cluster[self.sample_location[i]],\n",
    "                                                                           np.where(self.list_cluster[\n",
    "                                                                                        self.sample_location[i]] == i),\n",
    "                                                                           axis=0)\n",
    "                    self.sample_location[i] = index  # 记录该样本在类中的位置\n",
    "                    self.list_cluster[index] = np.concatenate((self.list_cluster[index], np.array([i])), axis=0)\n",
    "                    self.counter += 1\n",
    "            else:\n",
    "                self.sample_location[i] = index  # 记录该样本在类中的位置\n",
    "                self.list_cluster[index] = np.concatenate((self.list_cluster[index], np.array([i])), axis=0)\n",
    "                self.counter += 1\n",
    "\n",
    "    def calculate_iou(self, true_box, mean_):\n",
    "        \n",
    "        true_box_max = true_box/2.0\n",
    "        true_box_min = - true_box_max\n",
    "        anchor_box_max = mean_/2.0\n",
    "        anchor_box_min = -anchor_box_max\n",
    "        insect_min = np.maximum(true_box_min,anchor_box_min)\n",
    "        insect_max = np.minimum(true_box_max,anchor_box_max)\n",
    "        insect_wh = np.maximum(insect_max - insect_min,0.)\n",
    "        insect_area = insect_wh[0]*insect_wh[1]\n",
    "        \n",
    "        true_box_area = true_box[0] * true_box[1]\n",
    "        anchor_box_area = mean_[0] * mean_[1]\n",
    "        \n",
    "        assert(true_box_area>=0)\n",
    "        assert(anchor_box_area>=0)\n",
    "        assert(insect_area>=0)\n",
    "        \n",
    "        return insect_area/(true_box_area + anchor_box_area - insect_area)\n",
    "\n",
    "    def cal_mean(self, cluster):\n",
    "        mean_ = np.array([0, 0])\n",
    "        for index in cluster:\n",
    "            mean_ = mean_ + self.complete_size[index]\n",
    "        mean_ = mean_ / cluster.shape[0]\n",
    "        return mean_\n",
    "    def calculate_mean_iou(self):\n",
    "        mean_iou = 0.0\n",
    "        for i in range(self.k):\n",
    "            for j in range(self.list_cluster[i].shape[0]):\n",
    "                mean_iou+=self.calculate_iou(self.complete_size[self.list_cluster[i][j]],self.center_list[i])\n",
    "        mean_iou/=self.complete_size.shape[0]\n",
    "        return mean_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Writing_labels():\n",
    "    \"\"\"\n",
    "    这个类负责实现h5文件的生成\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, width=256, height=256):\n",
    "        \"\"\"\n",
    "\n",
    "        :param width: 一张图片的宽度\n",
    "        :param height: 一张图片的高度\n",
    "        \"\"\"\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "    def write(self, cluster_result, center_list, k, grid, xmllist, dict_classes,num_true_box, classes=3,\n",
    "              parent_path=r\"D:\\studyINF\\AI\\YOLOv3\\yolo_img3\"):\n",
    "        \"\"\"\n",
    "        :param cluster_result:  记载每个类的样本的序号\n",
    "        :param center_list:     记载每个类的中心点，即平均的宽高\n",
    "        :param classes:          我们要识别的类的数量\n",
    "        :param k:               每一个 gird cell 的 anchor box 的数量\n",
    "        :param grid:            一行(一列)， 有多少个 grid cell\n",
    "        :param xmllist:         xml 文件的文件名列表\n",
    "        :param dict_classes:    每个目标类及其对应的序号，组成的字典\n",
    "        num_true_box:           每张图片最多有多少个true_box\n",
    "        :param parent_path:\n",
    "        :return:                nothing\n",
    "        \"\"\"\n",
    "        img_counter = 0\n",
    "        sample_counter = 0\n",
    "        f = h5py.File(parent_path + '\\\\' + 'train_data2.h5', 'w')\n",
    "        f.create_dataset('images', shape=[len(xmllist), self.height, self.width, 3], dtype=np.uint8)\n",
    "        f.create_dataset('anchor_labels', shape=[len(xmllist), grid, grid, k, 5 + classes], dtype=np.float32)\n",
    "        f.create_dataset('true_box_labels', shape=[len(xmllist), num_true_box, 5], dtype=np.float32)\n",
    "        f.create_dataset(\"prior_boxes\",shape = [len(xmllist),grid,grid,k,4],dtype = np.float32)\n",
    "        \n",
    "        images = f[\"images\"]\n",
    "        anchor_labels = f[\"anchor_labels\"]\n",
    "        true_box_labels = f[\"true_box_labels\"]\n",
    "        prior_boxes = f[\"prior_boxes\"]\n",
    "        anchor_labels[:] = np.zeros(shape=[len(xmllist), grid, grid, k, 5 + classes], dtype=np.float32)\n",
    "        # 这里的 5 指[confidence, bx,by,bw,bh]\n",
    "        prior_boxes[:] = np.zeros(shape = [len(xmllist),grid,grid,k,4],dtype = np.float32)\n",
    "        # 这里的4 指[prior_x,prior_y,prior_w,prior_h]\n",
    "        for xmlfile in xmllist:\n",
    "            content = read_content(xmlfile)\n",
    "            img_path = re.findall('<path>(.*)</path>', content)[0]\n",
    "            #part_one, part_two = img_path.split(\"\\\\\")[-2::1]\n",
    "            #img_path = os.path.join(parent_path,part_one,part_one+part_two)\n",
    "            image = np.array(ndimage.imread(img_path, flatten=False))\n",
    "            images[img_counter] = image\n",
    "            # label 部分\n",
    "\n",
    "            # 计算中点位于哪个格子,计算相对于整一张图片的宽度,高度的中点的位置(宽度为单位长度)\n",
    "            grid_list, cen_coordinate, width_height = self.cal_center_wid_hei(content)\n",
    "            sample_counter += grid_list.shape[0]\n",
    "\n",
    "            which_anchor = self.confirm_anchor(grid_list.shape[0], sample_counter,\n",
    "                                               cluster_result)  # 确定其属于哪一个anchor box，\n",
    "\n",
    "\n",
    "            which_class = self.confirm_classes(dict_classes, content)  # 确定是哪一个目标类\n",
    "\n",
    "            temp_all = np.zeros(shape=[grid, grid, k, 5 + classes], dtype=np.float32)\n",
    "            temp2_all = np.zeros(shape=[grid, grid, k, 4],dtype= np.float32)\n",
    "            for i in range(grid_list.shape[0]):\n",
    "                temp = np.zeros(shape=[5 + classes], dtype=np.float32)\n",
    "                temp[0] = 1.0\n",
    "                temp[1:3] = cen_coordinate[i]\n",
    "                temp[3:5] = width_height[i]\n",
    "                temp[5 + which_class[i]] = 1.0\n",
    "                #print(\"grid_list[i,0] is :\", grid_list[i, 0])\n",
    "                #print(\"grid_list[i,1] is :\", grid_list[i, 1])\n",
    "                #print(\"which_anchor[i] is :\", which_anchor[i])\n",
    "                #print(\"temp is: \", temp)\n",
    "                temp_all[grid_list[i, 0], grid_list[i, 1], which_anchor[i]] = temp\n",
    "                \n",
    "                # 华丽的分割线\n",
    "                temp2 = np.zeros(shape=[4],dtype = np.float32)\n",
    "                temp2[0:2] = cen_coordinate[i]\n",
    "                temp2[2:4] = center_list[which_anchor[i]]/np.array([self.width,self.height])\n",
    "                temp2_all[grid_list[i, 0], grid_list[i, 1], which_anchor[i]] = temp2\n",
    "                # print(\"label is:\",labels[img_counter,grid_list[i,0],grid_list[i,1],which_anchor[i]])\n",
    "            anchor_labels[img_counter] = temp_all\n",
    "            prior_boxes[img_counter] = temp2_all\n",
    "            temp_true_box = self.write_true_box(content,dict_calsses,num_true_box)\n",
    "            true_box_labels[img_counter] = temp_true_box\n",
    "            img_counter += 1\n",
    "\n",
    "\n",
    "        f.close()\n",
    "    def write_true_box(self,original_string,dict_classes,num_true_box):\n",
    "        xmin = re.findall('<xmin>(\\\\d+)</xmin>', original_string)\n",
    "        ymin = re.findall('<ymin>(\\\\d+)</ymin>', original_string)\n",
    "        xmax = re.findall('<xmax>(\\\\d+)</xmax>', original_string)\n",
    "        ymax = re.findall('<ymax>(\\\\d+)</ymax>', original_string)\n",
    "        temp = np.zeros(shape=[num_true_box,5],dtype = np.int32)\n",
    "        which_class = self.confirm_classes(dict_classes,original_string)\n",
    "        for i in range(len(xmin)):\n",
    "            xmin[i] = int(xmin[i])\n",
    "            ymin[i] = int(ymin[i])\n",
    "            xmax[i] = int(xmax[i])\n",
    "            ymax[i] = int(ymax[i])\n",
    "            temp[i,4] = which_class[i]\n",
    "            temp[i,0:4] = np.array([(xmin[i] + xmax[i])//2/self.width , (ymin[i] + ymax[i])//2/self.height , (xmax[i] - xmin[i])/self.width ,(ymax[i] - ymin[i])/self.height])\n",
    "        return temp\n",
    "\n",
    "\n",
    "    def cal_center_wid_hei(self, content, width_per_grid=32, height_per_grid=32):\n",
    "        \"\"\"\n",
    "\n",
    "        :param content:  xml文件的内容\n",
    "        :param width_per_grid:  每个grid cell 的宽度\n",
    "        :param height_per_grid: 每个grid cell 的高度\n",
    "        :param width:  一张图片的宽度\n",
    "        :param height: 一张图片的高度\n",
    "        :return: grid_list, a np.array with shape(amount_sample,2)  indexes of grid part in  the \"training_y\"\n",
    "        :return: cen_coordinate, a np.array with shape(amount_sample,2),indexes of coordinate part in the \"training_y\"\n",
    "        \"\"\"\n",
    "\n",
    "        xmin = re.findall('<xmin>(\\\\d+)</xmin>', content)\n",
    "        ymin = re.findall('<ymin>(\\\\d+)</ymin>', content)\n",
    "        xmax = re.findall('<xmax>(\\\\d+)</xmax>', content)\n",
    "        ymax = re.findall('<ymax>(\\\\d+)</ymax>', content)\n",
    "\n",
    "        box_this_img = len(xmin)  # 这张图片的box的数量\n",
    "        for i in range(box_this_img):\n",
    "            xmin[i] = int(xmin[i])\n",
    "            ymin[i] = int(ymin[i])\n",
    "            xmax[i] = int(xmax[i])\n",
    "            ymax[i] = int(ymax[i])\n",
    "        xmin = np.array(xmin).reshape(-1, 1)\n",
    "        ymin = np.array(ymin).reshape(-1, 1)\n",
    "        xmax = np.array(xmax).reshape(-1, 1)\n",
    "        ymax = np.array(ymax).reshape(-1, 1)\n",
    "        \"\"\"\n",
    "\n",
    "        grid_list = [[0,0] for i in range(box_this_img)]\n",
    "        cen_coordinate = [[0,0] for i in range(box_this_img)]\n",
    "        width_height_list = [[0,0] for i in range(box_this_img)]\n",
    "\n",
    "        for i in range(box_this_img):\n",
    "            grid_list[i] = [(xmax[i] + xmin[i])/2 //width_per_grid ,(ymax[i] - ymin[i])/2//height_per_grid]\n",
    "            cen_coordinate[i] = []\n",
    "        \"\"\"\n",
    "        grid_list = np.concatenate(((ymax + ymin) / 2 // height_per_grid, (xmax + xmin) / 2 // width_per_grid),\n",
    "                                   axis=1).astype(np.int32)\n",
    "        cen_coordinate = np.concatenate(((xmax + xmin) / 2 / self.width, (ymax + ymin) / 2 / self.height), axis=1)\n",
    "        width_height = np.concatenate(((xmax - xmin)  / self.width, (ymax - ymin)  / self.height),axis = 1) # 以及计算相对的宽度和高度\n",
    "        return grid_list, cen_coordinate, width_height\n",
    "\n",
    "    def confirm_anchor(self, sample_this_img, sample_counter, cluster_result):\n",
    "        \"\"\"\n",
    "\n",
    "        :param sample_this_img:   该图片共有多少个 box\n",
    "        :param sample_counter:    到该图片为止，应有多少个box被记录进h5文件\n",
    "        :param cluster_result:    a list of three(k) arrays, every array records the sequence number of samples falling into the\n",
    "                                  relative cluster\n",
    "        :return:                  a list of anchor box ID indicating the anchor box which is responsible for the samples\n",
    "        \"\"\"\n",
    "        temp = []\n",
    "        for sample_num in range(sample_counter - sample_this_img, sample_counter):\n",
    "            for i in range(len(cluster_result)):\n",
    "                if sample_num in cluster_result[i]:\n",
    "                    temp.append(i)\n",
    "        return temp\n",
    "\n",
    "    def confirm_classes(self, dict_classes, content):\n",
    "        keys = re.findall(\"<name>(.+)</name>\", content)\n",
    "        temp = []\n",
    "        for key in keys:\n",
    "            temp.append(dict_classes[key])\n",
    "        return temp\n",
    "    def supplement_h5file(self,h5file_path,image_dir):\n",
    "        \"\"\"\n",
    "\n",
    "        :param h5file_path: The path of h5 file that we want to get data from\n",
    "        :return: nothing\n",
    "        这个函数是为了实现补充背景图片的数据的功能\n",
    "        \"\"\"\n",
    "        img_path_list = glob.glob(image_dir+\"\\\\\"+\"*.jpg\")\n",
    "        \n",
    "        f = h5py.File(h5file_path, 'r')\n",
    "        train_images = np.array(f['images'])\n",
    "        anchor_labels = np.array(f['anchor_labels'])\n",
    "        true_box_labels = np.array(f[\"true_box_labels\"])\n",
    "        prior_boxes = np.array(f[\"prior_boxes\"])\n",
    "        f.close()\n",
    "        background_images = np.zeros(shape=(len(img_path_list),) + train_images.shape[1:],dtype = train_images.dtype)\n",
    "        bg_anchor_labels = np.zeros(shape =(len(img_path_list),) + anchor_labels.shape[1:],dtype = anchor_labels.dtype)\n",
    "        bg_true_box_labels = np.zeros(shape = (len(img_path_list),) + true_box_labels.shape[1:] ,dtype = true_box_labels.dtype)\n",
    "        # bg 是背景的缩写\n",
    "        bg_prior_boxes = np.zeros(shape=(len(img_path_list),) + prior_boxes.shape[1:],dtype = prior_boxes.dtype)\n",
    "        for i,img_path in enumerate(img_path_list):\n",
    "            background_images[i] = ndimage.imread(img_path,flatten=False)\n",
    "        whole_images = np.concatenate((train_images,background_images),axis=0)\n",
    "        whole_anchor_labels = np.concatenate((anchor_labels,bg_anchor_labels),axis=0)\n",
    "        whole_true_box_labels = np.concatenate((true_box_labels,bg_true_box_labels),axis=0)\n",
    "        whole_prior_boxes = np.concatenate((prior_boxes,bg_prior_boxes),axis =0)\n",
    "        with h5py.File(h5file_path, 'w') as f:\n",
    "            f.create_dataset('images', shape=whole_images.shape, dtype=whole_images.dtype)\n",
    "            f.create_dataset('anchor_labels', shape=whole_anchor_labels.shape, dtype=whole_anchor_labels.dtype)\n",
    "            f.create_dataset('true_box_labels', shape=whole_true_box_labels.shape, dtype=whole_true_box_labels.dtype)\n",
    "            f.create_dataset(\"prior_boxes\",shape =  whole_prior_boxes.shape,dtype = whole_prior_boxes.dtype)\n",
    "            images = f[\"images\"]\n",
    "            anchor_labels = f[\"anchor_labels\"]\n",
    "            true_box_labels = f[\"true_box_labels\"]\n",
    "            prior_boxes = f[\"prior_boxes\"]\n",
    "            images[:] = whole_images\n",
    "            anchor_labels[:] = whole_anchor_labels\n",
    "            true_box_labels[:] = whole_true_box_labels\n",
    "            prior_boxes[:] = whole_prior_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len is: 698\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "dirname = r\"D:\\studyINF\\AI\\YOLOv3\\yolo_img3\"\n",
    "xmllist = glob.glob(dirname+ '\\\\*'+'\\\\'+'*.xml')\n",
    "print(\"len is:\",len(xmllist))\n",
    "max_value = 0\n",
    "for xmlfile in xmllist:\n",
    "    with open(xmlfile,\"r\",encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "        counter = content.count(\"bndbox\")\n",
    "        if counter>max_value:\n",
    "            max_value=counter\n",
    "max_value/=2\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([19.10628019, 17.5826087 ]),\n",
       " array([46.0840708 , 15.86283186]),\n",
       " array([27.35308953, 25.91424968]),\n",
       " array([17.62978723, 46.55744681]),\n",
       " array([55.46875, 28.96875]),\n",
       " array([50.859375, 85.40625 ]),\n",
       " array([92.13333333, 71.43333333]),\n",
       " array([33.04054054, 50.52702703])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one.center_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([19.07632094, 17.52739726]),\n",
       " array([45.97297297, 15.77927928]),\n",
       " array([27.28571429, 25.73086735]),\n",
       " array([16.81603774, 45.10849057]),\n",
       " array([53.87195122, 28.81097561]),\n",
       " array([50.42105263, 83.23684211]),\n",
       " array([92.86666667, 69.46666667]),\n",
       " array([31.02752294, 50.16055046])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one.center_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2765,)\n",
      "0.7460978022454268\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #np.seterr(\"raise\")\n",
    "    dirname = r\"D:\\studyINF\\AI\\YOLOv3\\yolo_img3\"\n",
    "    xmllist = glob.glob(dirname+ '\\\\*'+'\\\\'+'*.xml')\n",
    "    #print(len(xmllist))\n",
    "    \n",
    "    xmin, xmax, ymin, ymax = start(xmllist)\n",
    "    #print(xmin.dtype)\n",
    "    #print(xmax.dtype)\n",
    "    np_width = xmax - xmin\n",
    "    np_height = ymax - ymin\n",
    "    print(np_width.shape)\n",
    "    \n",
    "    complete_size = np.concatenate((np_width.reshape(np_width.shape[0], 1), np_height.reshape(np_height.shape[0], 1)),\n",
    "                                  axis=1)\n",
    "    amount_cluster = 8\n",
    "    one  = cluster_anchor(complete_size, amount_cluster)\n",
    "    print(one.calculate_mean_iou())\n",
    "    instance = Writing_labels(width = 416, height=416)\n",
    "    dict_calsses = get_dict_class(path=r\"D:\\studyINF\\AI\\2.7code\\opencv\\yolonet\\yolo_img2\\labels.txt\")\n",
    "    instance.write(one.list_cluster,one.center_list,k=amount_cluster,grid=13,xmllist=xmllist,dict_classes=dict_calsses,classes=3,num_true_box = 10,parent_path =r\"D:\\studyINF\\AI\\YOLOv3\\yolo_img3\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "instance = Writing_labels(width = 416, height=416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance.supplement_h5file(r\"D:\\studyINF\\AI\\YOLOv3\\yolo_img3\\train_data2.h5\",r\"D:\\studyINF\\AI\\YOLOv3\\yolo_img3\\background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readh5(h5_path):\n",
    "    f = h5py.File(h5_path, 'r')\n",
    "    #train_images = np.array(f['images'])\n",
    "    train_labels = np.array(f['anchor_labels'])\n",
    "    prior_boxes = np.array(f[\"prior_boxes\"])\n",
    "    f.close()\n",
    "    return  train_labels, prior_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_iou( true_box, mean_):\n",
    "        true_box_max = true_box/2.0\n",
    "        true_box_min = - true_box_max\n",
    "        anchor_box_max = mean_/2.0\n",
    "        anchor_box_min = -anchor_box_max\n",
    "        insect_min = np.maximum(true_box_min,anchor_box_min)\n",
    "        insect_max = np.minimum(true_box_max,anchor_box_max)\n",
    "        insect_wh = np.maximum(insect_max - insect_min,0.)\n",
    "        insect_area = insect_wh[0]*insect_wh[1]\n",
    "        \n",
    "        true_box_area = true_box[0] * true_box[1]\n",
    "        anchor_box_area = mean_[0] * mean_[1]\n",
    "        return insect_area/(true_box_area + anchor_box_area - insect_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_mean = [np.array([31.68817204, 51.02150538]),\n",
    " np.array([25.90733591, 31.56756757]),\n",
    " np.array([21.43287037, 22.81712963]),\n",
    " np.array([47.12258065, 14.56129032]),\n",
    " np.array([51.58490566, 24.90566038]),\n",
    " np.array([18.62641509, 15.61132075])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51.58490566, 24.90566038])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp =[]\n",
    "sample = np.array([63,20])\n",
    "for i in range(len(all_mean)):\n",
    "    temp.append(calculate_iou(sample,all_mean[i]))\n",
    "all_mean[np.argmax(np.array(temp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anchors,prior_boxes = readh5(r\"D:\\studyINF\\AI\\YOLOv3\\yolo_img3\\train_data2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File(r\"D:\\studyINF\\AI\\YOLOv3\\yolo_img3\\train_data2.h5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor_labels\n",
      "images\n",
      "prior_boxes\n",
      "true_box_labels\n"
     ]
    }
   ],
   "source": [
    "for key in f.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[19.07632094, 17.52739726],\n",
    "[45.97297297, 15.77927928],\n",
    "[27.28571429, 25.73086735],\n",
    "[16.81603774, 45.10849057],\n",
    "[53.87195122, 28.81097561],\n",
    "[50.42105263, 83.23684211],\n",
    "[92.86666667, 69.46666667],\n",
    "[31.02752294, 50.16055046]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = np.ones(shape = [3,3],dtype =np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = temp.tostring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
